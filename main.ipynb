{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports autoreload for on-the-fly modifications\n",
    "from importlib import reload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions file\n",
    "import functions as f\n",
    "reload(f)\n",
    "%aimport functions\n",
    "\n",
    "# import modules\n",
    "import os\n",
    "\n",
    "import scipy as sc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from sqlalchemy import create_engine, text, inspect, Table, Column, Integer, String, MetaData, ForeignKey\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.contingency import association\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing datasheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographic data from clients\n",
    "final_demo = pd.read_csv('sources/raw/df_final_demo.txt', sep=',')\n",
    "\n",
    "# test vs control groups\n",
    "final_exp = pd.read_csv('sources/raw/df_final_experiment_clients.txt', sep=',')\n",
    "\n",
    "# raw data from clients\n",
    "data1 = pd.read_csv('sources/raw/df_final_web_data_pt_1.txt', sep=',')\n",
    "data2 = pd.read_csv('sources/raw/df_final_web_data_pt_2.txt', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(final_demo.head(5))\n",
    "display(final_exp.head(5))\n",
    "display(data1.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating an engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL credentials in .env\n",
    "load_dotenv()\n",
    "password = os.getenv('PASSWORD')\n",
    "\n",
    "# Create the Database\n",
    "database_name = 'project5'\n",
    "# Set Up Database Connection\n",
    "engine = create_engine(f'mysql+pymysql://root:{password}@localhost')\n",
    "# Create Database if it Doesn't Exist\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f'CREATE DATABASE IF NOT EXISTS {database_name}'))\n",
    "# Connect to the Newly Created Database\n",
    "engine = create_engine(f'mysql+pymysql://root:{password}@localhost/{database_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **METADATA**\n",
    "- **client_id**: Every client’s unique ID.\n",
    "- **variation**: Indicates if a client was part of the experiment.\n",
    "- **visitor_id**: A unique ID for each client-device combination.\n",
    "- **visit_id**: A unique ID for each web visit/session.\n",
    "- **process_step**: Marks each step in the digital process.\n",
    "- **date_time**: Timestamp of each web activity.\n",
    "- **clnt_tenure_yr**: Represents how long the client has been with Vanguard, measured in years.\n",
    "- **clnt_tenure_mnth**: Further breaks down the client’s tenure with Vanguard in months.\n",
    "- **clnt_age**: Indicates the age of the client.\n",
    "- **gendr**: Specifies the client’s gender.\n",
    "- **num_accts**: Denotes the number of accounts the client holds with Vanguard.\n",
    "- **bal**: Gives the total balance spread across all accounts for a particular client.\n",
    "- **calls_6_mnth**: Records the number of times the client reached out over a call in the past six months.\n",
    "- **logons_6_mnth**: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DEMOGRAPHICS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first inspection on the demographics file\n",
    "display(final_demo.shape)\n",
    "display(final_demo.head())\n",
    "display(final_demo.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN rows\n",
    "final_demo2 = final_demo[final_demo.isnull().sum(axis=1) < 2]\n",
    "final_demo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender fix\n",
    "final_demo2[\"gendr\"] = final_demo2[\"gendr\"].replace({\"X\":\"U\"})\n",
    "final_demo2[\"gendr\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "final_demo2 = final_demo2.rename(columns={\"clnt_tenure_yr\":\"tenure_year\", \"clnt_tenure_mnth\":\"tenure_month\", \"clnt_age\":\"age\", \"gendr\":\"gender\",\"num_accts\":\"number_accounts\", \"calls_6_mnth\":\"calls_6_months\",\"logons_6_mnth\":\"logons_6_months\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_demo2[\"age_group\"] = final_demo2[\"age\"].apply(f.age_group)\n",
    "\n",
    "display(final_demo2)\n",
    "final_demo2.to_sql(\"demo2\", con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **First EDA on demography**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_demo3 = final_demo2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [\"tenure_month\", \"age\", \"number_accounts\",\"bal\" , \"calls_6_months\" , \"logons_6_months\"]\n",
    "\n",
    "f.hist_box_plot(final_demo3, check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.categorical_display(final_demo3, \"gender\")\n",
    "f.categorical_display(final_demo3, \"age_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.categorical_comparison(final_demo3, \"age_group\", \"bal\")\n",
    "\n",
    "# bal by age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'age_group' and sum 'logons_6_months'\n",
    "l1 = final_demo3.groupby([\"age_group\"])[\"logons_6_months\"].sum().reset_index()\n",
    "\n",
    "l1[\"order\"]=l1[\"age_group\"].map(f.order_group)\n",
    "l1 = l1.sort_values(by=\"order\")\n",
    "l1 = l1.set_index(\"order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot using the aggregated counts\n",
    "sns.barplot(data=l1, x='age_group', y='logons_6_months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'age_group' and sum 'logons_6_months'\n",
    "l2 = final_demo3.groupby([\"age_group\", \"gender\"])[\"logons_6_months\"].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2[\"order\"]=l2[\"age_group\"].map(f.order_group)\n",
    "l2[\"order\"]=l2[\"order\"]+l2[\"gender\"].map(f.order_gender)\n",
    "l2 = l2.sort_values(by=\"order\")\n",
    "l2 = l2.set_index(\"order\")\n",
    "\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "sns.barplot(data=l2, x='age_group', y='logons_6_months', hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'age_group' and sum 'logons_6_months'\n",
    "l3 = final_demo3.groupby([\"age_group\", \"gender\"])[\"tenure_month\"].mean().reset_index()\n",
    "\n",
    "l3[\"order\"]=l3[\"age_group\"].map(f.order_group)\n",
    "l3[\"order\"]=l3[\"order\"]+l3[\"gender\"].map(f.order_gender)\n",
    "l3 = l3.sort_values(by=\"order\")\n",
    "l3 = l3.set_index(\"order\")\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(data=l3, x='age_group', y='tenure_month', hue='gender')\n",
    "\n",
    "# Move the legend outside the plot\n",
    "plt.legend(title='gender', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "l3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Who are the primary clients using this online process?**\n",
    "\n",
    "From these barplots we can clearly see that the primary client (the one with most usage) is the old adult category (ages between 50-65).\n",
    "Gender wise, Unspecified lead the race, with Males following close behind.\n",
    "Once all data is being grouped, we see that young adults (age 18-35) with unspecified gender have the highest usage, followed by both male and female old adults.\n",
    "\n",
    "#####  **2. Are the primary clients younger or older, new or long-standing?**\n",
    "\n",
    "Regarding tenure, we clearly see Elder (age > 65) has the higher numbers, with an average of over 200 months for both Male and Female genders, followed by teenagers (age < 18) and old adults with around 195 months on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECOND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(final_exp.shape)\n",
    "display(final_exp.head())\n",
    "final_exp.isna().sum()\n",
    "\n",
    "#output to sql\n",
    "#final_exp.to_sql(\"experience\", con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THIRD DATASET + FOURTH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data1.shape)\n",
    "display(data1.head(3))\n",
    "display(data2.shape)\n",
    "display(data2.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins data1 and data2 files, sends to SQL\n",
    "t_data = pd.concat([data1, data2], axis=0)\n",
    "#t_data.to_sql(\"dataset\", con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting A/B construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SQL, joins tables and retrieves the association between the datasheet and the variation table.\n",
    "\"\"\"\n",
    "statement = (\"\"\" \"\"\"\n",
    "            SELECT d.client_id, e.Variation, d.visitor_id, d.visit_id, d.process_step, d.date_time\n",
    "            FROM dataset as d\n",
    "            LEFT JOIN experience as e             \n",
    "            ON d.client_id = e.client_id\n",
    "            WHERE e.Variation IS NOT NULL\n",
    "            ;\n",
    "            \"\"\" \"\"\")\n",
    "with engine.connect() as con:\n",
    "    try:\n",
    "        # Execute the query to fetch results\n",
    "        answer = pd.read_sql(statement, con)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "answer.to_sql(\"dataset2\", con=engine, if_exists=\"replace\")\n",
    "answer.to_csv(\"sources/clean/answer.csv\")\n",
    "answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv(\"sources/clean/answer.csv\")\n",
    "\n",
    "## Cleanup \n",
    "display(answer.shape)\n",
    "answer = answer.drop_duplicates().sort_values(by=\"date_time\").drop(\"Unnamed: 0\", axis=1).reset_index(drop=True)\n",
    "answer = answer.drop(\"visitor_id\", axis=1)\n",
    "\n",
    "answer2 = answer.copy()\n",
    "\n",
    "answer2['date_time'] = pd.to_datetime(answer2['date_time'])\n",
    "\n",
    "answer_clean = f.clean_data(answer2, \"answer_clean\")\n",
    "answer_clean.to_csv(\"sources/clean/answer_clean.csv\")\n",
    "\n",
    "answer_clean = pd.read_csv(\"sources/clean/answer_clean.csv\", index_col=0)\n",
    "\n",
    "#display(answer_clean.head(3))\n",
    "\n",
    "answer_clean['start_date'] = pd.to_datetime(answer_clean['start_date'])\n",
    "answer_clean['step_1_date'] = pd.to_datetime(answer_clean['step_1_date'])\n",
    "answer_clean['step_2_date'] = pd.to_datetime(answer_clean['step_2_date'])\n",
    "answer_clean['step_3_date'] = pd.to_datetime(answer_clean['step_3_date'])\n",
    "answer_clean['confirm_date'] = pd.to_datetime(answer_clean['confirm_date'])\n",
    "\n",
    "#display(answer_clean.dtypes)\n",
    "\n",
    "answer_clean[\"SS1\"] = (answer_clean['step_1_date'] - answer_clean['start_date']).dt.total_seconds()\n",
    "answer_clean[\"S1S2\"] = (answer_clean['step_2_date'] - answer_clean['step_1_date']).dt.total_seconds()\n",
    "answer_clean[\"S2S3\"] = (answer_clean['step_3_date'] - answer_clean['step_2_date']).dt.total_seconds()\n",
    "answer_clean[\"S3C\"] = (answer_clean['confirm_date'] - answer_clean['step_3_date']).dt.total_seconds()\n",
    "answer_clean[\"SC\"] = (answer_clean['confirm_date'] - answer_clean['start_date']).dt.total_seconds()\n",
    "\n",
    "answer_clean[\"completed\"] = answer_clean.apply(lambda row: 1 if (\n",
    "    pd.notna(row[\"start_date\"]) & \n",
    "    pd.notna(row[\"confirm_date\"])) else 0, axis=1)\n",
    "\n",
    "#display(answer_clean.head(3))\n",
    "\n",
    "# splitting A\n",
    "A_answer = answer_clean[answer_clean[\"variation\"]==\"Test\"].reset_index(drop=True)\n",
    "A_answer.to_csv(\"sources/clean/A_answer.csv\")\n",
    "\n",
    "# splitting B\n",
    "B_answer = answer_clean[answer_clean[\"variation\"]==\"Control\"].reset_index(drop=True)\n",
    "B_answer.to_csv(\"sources/clean/B_answer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_clean = pd.read_csv(\"sources/clean/A_answer.csv\", index_col=0)\n",
    "B_clean = pd.read_csv(\"sources/clean/B_answer.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ho -> time per step is equal for both features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\"SS1\", \"S1S2\" , \"S2S3\", \"S3C\",\"SC\"]\n",
    "sign = 0.05\n",
    "\n",
    "for step in steps:\n",
    "    s_stat, s_pval = st.ttest_ind(A_clean[step].dropna(),B_clean[step].dropna(), equal_var=False)\n",
    "    print(f\"{step}: stat = {round(s_stat,3)}, p-value = {round(s_pval,3)}\")\n",
    "    if s_pval > sign:\n",
    "        print(f\"For {step} we cannot reject H0: our samples are similar.\")\n",
    "    if s_pval < sign:\n",
    "        print(f\"For {step} we reject H0: our samples are different.\")\n",
    "    print(A_clean[step].mean(),B_clean[step].mean(),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "A_plot=A_clean[[\"SS1\", \"S1S2\",\"S2S3\",\"S3C\",\"SC\"]]\n",
    "sns.lineplot(A_plot.mean(), color = \"red\" )\n",
    "\n",
    "# control\n",
    "B_plot=B_clean[[\"SS1\", \"S1S2\",\"S2S3\",\"S3C\", \"SC\"]]\n",
    "sns.lineplot(B_plot.mean(), color = \"green\" )\n",
    "\n",
    "row = \"SC\"\n",
    "mean_A = A_clean[row].mean()\n",
    "mean_B = B_clean[row].mean()\n",
    "\n",
    "display(f\"A:{mean_A} / B:{mean_B}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H0 -> completion/success rate from the new feature is equal to the old feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linh's code\n",
    "\n",
    "A_clean['completed'] = A_clean['confirm_date'].notnull().astype(int)\n",
    "B_clean['completed'] = B_clean['confirm_date'].notnull().astype(int)\n",
    "total_A = len(A_clean)\n",
    "total_B = len(B_clean)\n",
    "completed_A = A_clean['completed'].sum()\n",
    "completed_B = B_clean['completed'].sum()\n",
    "not_completed_A = len(A_clean) - completed_A\n",
    "not_completed_B = len(B_clean) - completed_B\n",
    "# Calculate completion rates\n",
    "completion_rate_A = completed_A / total_A\n",
    "completion_rate_B = completed_B / total_B\n",
    "\n",
    "thresh = completion_rate_B*1.05\n",
    "#display(round(float(thresh),5))\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Group': ['Test (New Design)','Control (Old Design)'],\n",
    "    'Completion Rate': [completion_rate_A, completion_rate_B]\n",
    "})\n",
    "# Step 4: Create bar plot to compare completion rates\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Group', y='Completion Rate', data=data, palette='muted')\n",
    "plt.axhline(y=thresh, color='red', linestyle='--', label='Fixed Y Value')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Comparison of Completion Rates Between Old and New Design')\n",
    "plt.ylabel('Completion Rate')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "# Create the contingency table\n",
    "contingency_table = np.array([[completed_A, not_completed_A], [completed_B, not_completed_B]])\n",
    "print(contingency_table)\n",
    "# Step 3: Perform the chi-squared test\n",
    "chi2, p_value, _, __ = chi2_contingency(contingency_table)\n",
    "# Step 4: Interpret the result\n",
    "alpha = 0.05  # Significance level\n",
    "print(f\"Chi-squared statistic: {chi2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. The variables are independent.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The variables are dependant.\")\n",
    "     \n",
    " \n",
    "success = [completed_A, completed_B]\n",
    "tests = [total_A, total_B]\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "stats, p_value = proportions_ztest(success, tests)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"Because p_value: {round(p_value,4)} < alpha: {alpha} we can reject the null.\")\n",
    "else:\n",
    "    print(f\"Because p_value: {round(p_value,4)} > alpha: {alpha}, we cannot reject the null.\")\n",
    "    \n",
    "display(round(completion_rate_A,3)*100)\n",
    "display(round(completion_rate_B,3)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design Effectiveness\n",
    "merged_df = pd.merge(final_demo3, final_exp, on='client_id', how='inner')\n",
    "\n",
    "group_counts = merged_df['Variation'].value_counts()\n",
    "\n",
    "avg_age_gender_group = merged_df.groupby(['gender', 'Variation'])['age'].mean().reset_index()\n",
    "\n",
    "test_design = merged_df[merged_df['Variation'] == \"Test\"]\n",
    "control_design = merged_df[merged_df['Variation'] == \"Control\"]\n",
    "control_design['age'] = control_design['age'].fillna(0).astype(int)\n",
    "test_design['age'] = test_design['age'].fillna(0).astype(int)\n",
    "test_design['gender'] = test_design['gender'].astype('category')\n",
    "control_design['gender'] = control_design['gender'].astype('category')\n",
    "\n",
    "#Was the experiment well-structured?\n",
    "def check_structured(new, old):\n",
    "    if new.shape[0] == old.shape[0]:\n",
    "        return \"Experiment was well structured\"\n",
    "    else:\n",
    "        return \"Imbalance\"\n",
    "    \n",
    "check_structured(test_design, control_design)\n",
    "\n",
    "#Were clients randomly and equally divided between the old and new designs?\n",
    "avg_age_test = test_design['age'].mean()\n",
    "avg_age_control = control_design['age'].mean()\n",
    "\n",
    "gender_control = control_design['gender'].value_counts(normalize=True)\n",
    "gender_test = test_design['gender'].value_counts(normalize=True)\n",
    "\n",
    "#Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=group_counts.index, y=group_counts.values, palette='muted')\n",
    "plt.title('Number of Clients in Test and Control Groups')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Number of Clients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process flow: start -> step_1 -> step_2 -> step_3 -> confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_answer2 = answer[answer[\"Variation\"]==\"Test\"]\n",
    "\n",
    "\n",
    "A_grouped = A_answer2.groupby([\"process_step\"])[\"visit_id\"].count().reset_index()\n",
    "\n",
    "A_grouped[\"ordered\"]=A_grouped[\"process_step\"].map(f.ordered_grouped)\n",
    "A_grouped.sort_values(by= \"ordered\", inplace=True)\n",
    "A_grouped = A_grouped.set_index(\"ordered\")\n",
    "\n",
    "A_grouped[\"percentage\"]=round(A_grouped[\"visit_id\"]/A_grouped[\"visit_id\"][0] * 100,2)\n",
    "A_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_answer2 = answer[answer[\"Variation\"]==\"Control\"]\n",
    "\n",
    "B_grouped = B_answer2.groupby([\"process_step\"])[\"visit_id\"].count().reset_index()\n",
    "\n",
    "B_grouped[\"ordered\"]=B_grouped[\"process_step\"].map(f.ordered_grouped)\n",
    "B_grouped.sort_values(by= \"ordered\", inplace=True)\n",
    "B_grouped = B_grouped.set_index(\"ordered\")\n",
    "\n",
    "B_grouped[\"percentage\"]=round(B_grouped[\"visit_id\"]/B_grouped[\"visit_id\"][0] * 100,2)\n",
    "B_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(A_grouped[['process_step', 'visit_id']], \n",
    "                     B_grouped[['process_step', 'visit_id']], \n",
    "                     on='process_step', suffixes=('_A', '_B'))\n",
    "\n",
    "completation_rate_df = merged_df[merged_df['process_step'].isin(['start', 'confirm'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a contingency table from merged dataframes\n",
    "contingency_table = completation_rate_df[['visit_id_A', 'visit_id_B']]\n",
    "print(contingency_table)\n",
    "\n",
    "#Chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# we conclude the samples are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cramer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the association between variables in 'crosstab_result' using the \"cramer\" method\n",
    "crosstab_result = pd.crosstab(contingency_table['visit_id_A'], contingency_table ['visit_id_B'])\n",
    "\n",
    "association(crosstab_result, method=\"cramer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing A/B Testing, we recognized that there is a statistically significant difference in completion rate between the two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first remarks\n",
    "\n",
    "From basic analysis of group A vs B we can see that from those starting, only 62% reached step1 vs our new-feature's 68.7%. However, step2 is almost tied, which seem to point out towards an issue with step1 that needs improving. New features on step are worsening the score, 46% vs 48% on the old system, but the overall score (so those that complete the steps and confirm) we do see an improvement, showing that the new feature is indeed more efficient (45.6% vs 36.8% on the new feature). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "completion rate -> completion vs version? \n",
    "contingency_table = pd.crosstab(df['completion'],df['variation'])\n",
    "\n",
    "Ho they are independant\n",
    "H1 they are not independant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ho -> % success PER age_group is equal to the old feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KPI to evaluate**\n",
    "\n",
    "- Define the KPIs you chose to evaluate the new design’s performance.\n",
    "- Compare the KPIs for the Control Group vs. the Test Group.\n",
    "- Present visual aids to support the KPI analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics:\n",
    "Work objective is comparing 2 applications (one current, one new) and analyze it's perfomance (if it's better for the end user)\n",
    "\n",
    "- Is the program more user-friendly? (KPIs - %completion rate, %errors)\n",
    "- Is the program more efficient? (KPIs - Time Spent on Each Step, cost-efficient for implementation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Analyzing A/B Test Results:\n",
    "\n",
    "1. **Collect Data:** Track and gather data on how each group interacts with the content.\n",
    "2. **Statistical Analysis:** Use statistical tests (e.g., t-test) to determine if the differences observed are statistically significant.\n",
    "3. **Draw Conclusions:** If Version B significantly outperforms Version A, consider implementing the change. If not, revert to the original or consider new tests.\n",
    "\n",
    "**Note**: in this week's project, you'll be analyzing A/B Test Results, since the design and the collection of data was already done.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis Testing\n",
    "\n",
    "As part of your analysis, you’ll conduct hypothesis testing to make data-driven conclusions about the effectiveness of the redesign. See the full details below:\n",
    "\n",
    "- Completion Rate: Given the data and KPIs you have explored discussed, one interesting hypothesis to test is related to the completion rate between the Test and Control groups. Since the new design (Test group) had a higher completion rate compared to the old design (Control group), you are required to confirm if this difference is statistically significant.\n",
    "\n",
    "Make sure to define the proper null and an alternative hypothesis to test it. Use the provided data to test these hypotheses, and determine if you can reject the null hypothesis in favor of the alternative. Make sure to consider the significance level, p-value, the statistical test prerequisites, and other relevant statistical measures in your analysis.\n",
    "\n",
    "- Completion Rate with a Cost-Effectiveness Threshold: The introduction of a new UI design comes with its associated costs: design, development, testing, potential training for staff, and possible short-term disruptions or adjustments for users. To justify these costs, Vanguard has determined that any new design should lead to a minimum increase in the completion rate to be deemed cost-effective.\n",
    "\n",
    "Threshold: Vanguard has set this minimum increase in completion rate at 5%. This is the rate at which the projected benefits, in terms of increased user engagement and potential revenue, are estimated to outweigh the costs of the new design.\n",
    "\n",
    "You are required to carry out another analysis, ensuring that the observed increase in completion rate from the A/B test meets or exceeds this 5% threshold. If the new design doesn’t lead to at least this level of improvement, it may not be justifiable from a cost perspective, regardless of its statistical significance.\n",
    "\n",
    "- Other Hypothesis Examples\n",
    "You have been given the freedom to choose another hypothesis to test. Here are some examples:\n",
    "\n",
    "You might want to test whether the average age of clients engaging with the new process is the same as those engaging with the old process\n",
    "You might want to test if the average client tenure (how long they’ve been with Vanguard) of those engaging with the new process is the same as those engaging with the old process\n",
    "You might want to test if there are gender differences that affect engaging with the new or old process\n",
    "Make sure to define the proper null and alternative hypothesis to test it. You are required to choose one or come up with another of your own to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographic data from clients\n",
    "demo_exp = pd.merge(left = final_demo3, right = final_exp, on=\"client_id\")\n",
    "\n",
    "#demo_exp[\"Variation\"].unique() # array([nan, 'Test', 'Control'], dtype=object)\n",
    "\n",
    "demo_test = demo_exp[demo_exp[\"Variation\"]==\"Test\"]\n",
    "demo_control = demo_exp[demo_exp[\"Variation\"]==\"Control\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_test.head(5)\n",
    "\n",
    "## test clients\n",
    "demo_test_count = demo_test[\"client_id\"].count()\n",
    "demo_test_age = demo_test.groupby(\"age_group\")[\"client_id\"].count().reset_index()\n",
    "\n",
    "sns.barplot(demo_test_age, x = \"age_group\", y=\"client_id\", hue=\"age_group\")\n",
    "plt.title(\"Test clients by age_group\")\n",
    "plt.ylabel(\"Nr. of clients\")\n",
    "plt.show()\n",
    "\n",
    "## control clients\n",
    "demo_control_count = demo_control[\"client_id\"].count()\n",
    "demo_control_age = demo_control.groupby(\"age_group\")[\"client_id\"].count().reset_index()\n",
    "\n",
    "sns.barplot(demo_control_age, x = \"age_group\", y=\"client_id\", hue=\"age_group\")\n",
    "plt.title(\"Control clients by age_group\")\n",
    "plt.ylabel(\"Nr. of clients\")\n",
    "plt.show()\n",
    "\n",
    "## counts clients\n",
    "total_demo_count = demo_test_count + demo_control_count\n",
    "\n",
    "print(f\"Our total sample has {int(total_demo_count)} clients, with {int(demo_test_count)} test clients ({round(demo_test_count/total_demo_count*100,3)}%) and {int(demo_control_count)} control clients ({round(demo_control_count/total_demo_count*100,3)}%).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_age = pd.merge(demo_test_age, demo_control_age, on= \"age_group\").rename(columns={\"client_id_x\":\"test_group\",\"client_id_y\":\"control_group\"})\n",
    "\n",
    "df_long = pd.melt(demo_age, id_vars=['age_group'], value_vars=['test_group', 'control_group'],\n",
    "                  var_name='group', value_name='value')\n",
    "\n",
    "## is age_group equally distributed between test and control groups?\n",
    "\n",
    "sns.barplot(data=df_long, x='age_group', y='value', hue='group')\n",
    "plt.legend(title=\"Data groups\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylabel(\"Nr. of Clients\")\n",
    "plt.xlabel(\"Age group of clients\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_age\n",
    "\n",
    "# Calculating the Pearson correlation coefficient between 'test_group' and 'control_group' columns\n",
    "p_correlation = demo_age['test_group'].corr(demo_age['control_group'])\n",
    "p_correlation\n",
    "\n",
    "# Calculating the Spearman rank corr between 'test_group' and 'control_group' columns\n",
    "s_correlation = demo_age['test_group'].corr(demo_age['control_group'], method='spearman')\n",
    "s_correlation\n",
    "\n",
    "print(f\"Pearson's correlation coef: {round(p_correlation,5)}, Spearman's rank: {round(s_correlation,5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a contingency table from merged dataframes\n",
    "ct_table = demo_age[['test_group', 'control_group']]\n",
    "print(ct_table)\n",
    "\n",
    "#Chi-square test\n",
    "chi2_ct, p_value_ct, _, _ = chi2_contingency(ct_table)\n",
    "print(f\"Chi-square statistic: {chi2_ct}\")\n",
    "print(f\"P-value: {p_value_ct}\")\n",
    "\n",
    "sig=0.05\n",
    "\n",
    "#H0: samples are independant regardless of age_Group.\n",
    "\n",
    "if p_value_ct < sig:\n",
    "    print(\"Reject the null hypothesis.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = pd.concat([A_answer, B_answer])\n",
    "\n",
    "demo_age[demo_age[\"age_group\"]==\"teenager\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned2 = data_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned2[\"date_time\"] = 0\n",
    "\n",
    "data_cleaned2[\"date_time\"] = data_cleaned2.apply(lambda row: row[\"start_date\"] if pd.notna(row[\"start_date\"]) else row[\"confirm_date\"], axis=1)\n",
    "\n",
    "data_cleaned2[\"completed\"] = data_cleaned2.apply(lambda row: 1 if (\n",
    "    pd.notna(row[\"start_date\"]) & \n",
    "    pd.notna(row[\"confirm_date\"])) else 0, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"A: {total_A} total / {completed_A} completed.\")\n",
    "print(f\"B: {total_B} total / {completed_B} completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_clean = data_cleaned2[data_cleaned2[\"variation\"]==\"Test\"]\n",
    "B_clean = data_cleaned2[data_cleaned2[\"variation\"]==\"Control\"]\n",
    "\n",
    "A_clean_c = A_clean[A_clean[\"completed\"] == 1]\n",
    "B_clean_c = B_clean[B_clean[\"completed\"] == 1]\n",
    "\n",
    "A_clean['date_time'] = pd.to_datetime(A_clean['date_time'])\n",
    "A_clean_c['date_time'] = pd.to_datetime(A_clean_c['date_time'])\n",
    "\n",
    "B_clean['date_time'] = pd.to_datetime(B_clean['date_time'])\n",
    "B_clean_c['date_time'] = pd.to_datetime(B_clean_c['date_time'])\n",
    "\n",
    "weekly_activity = A_clean.set_index('date_time').resample('W').size().reset_index()\n",
    "weekly_completion = A_clean_c.set_index('date_time').resample('W').size().reset_index()\n",
    "weekly_activity = pd.merge(left = weekly_activity, right = weekly_completion, on=\"date_time\").rename(columns={\"0_x\":\"total\",\"0_y\":\"completed\"})\n",
    "\n",
    "weekly_activity2 = B_clean.set_index('date_time').resample('W').size().reset_index()\n",
    "weekly_completion2 = B_clean_c.set_index('date_time').resample('W').size().reset_index()\n",
    "weekly_activity2 = pd.merge(left = weekly_activity2, right = weekly_completion2, on=\"date_time\").rename(columns={\"0_x\":\"total\",\"0_y\":\"completed\"})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Reshape the data into long format\n",
    "df_long = weekly_activity.melt(id_vars=\"date_time\", value_vars=['total', 'completed'], \n",
    "                  var_name='status', value_name='count')\n",
    "weekly_activity = weekly_activity.set_index('date_time')\n",
    "weekly_activity[\"complete_rate_%\"] = weekly_activity.apply(lambda x: round((x[\"completed\"] / x[\"total\"]),3)*100 if x[\"total\"] > 0 else 0, axis=1)\n",
    "\n",
    "# Reshape the data into long format\n",
    "df_long2 = weekly_activity2.melt(id_vars=\"date_time\", value_vars=['total', 'completed'], \n",
    "                  var_name='status', value_name='count')\n",
    "weekly_activity2 = weekly_activity2.set_index('date_time')\n",
    "weekly_activity2[\"complete_rate_%\"] = weekly_activity2.apply(lambda x: round((x[\"completed\"] / x[\"total\"]),3)*100 if x[\"total\"] > 0 else 0, axis=1)\n",
    "\n",
    "\n",
    "# Plot the A data using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y='date_time', x='count', hue='status', data=df_long)\n",
    "plt.title('Test user Activity Per Week During the Experiment')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.xticks(rotation=0)\n",
    "#plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the B data using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y='date_time', x='count', hue='status', data=df_long2)\n",
    "plt.title('Control User Activity Per Week During the Experiment')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Number of Visits')\n",
    "plt.xticks(rotation=0)\n",
    "#plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "week = weekly_activity.merge(weekly_activity2, on = \"date_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge phase\n",
    "demo_answer = answer_clean.merge(final_demo3, how = \"left\", on=\"client_id\")\n",
    "\n",
    "# cleans absent clients from demographics\n",
    "demo_answer = demo_answer[~demo_answer[\"age_group\"].isna()]\n",
    "\n",
    "demo_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_answer.to_csv(\"sources/clean/demo_answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = demo_answer.groupby(\"age_group\")[\"client_id\"].count().reset_index()\n",
    "\n",
    "dd[\"order\"] = dd[\"age_group\"]\n",
    "\n",
    "dd[\"order\"] = dd[\"order\"].replace({\"teenager\":0, \"young_adult\":1, \"adult\":2, \"old_adult\":3, \"elder\":4})\n",
    "dd = dd.sort_values(by=\"order\")\n",
    "dd = dd.set_index(\"order\")\n",
    "\n",
    "sns.barplot(dd, x=\"age_group\", y=\"client_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for numerical columns in Test and Control groups\n",
    "test_group = demo_answer[demo_answer['variation'] == 'Test']\n",
    "control_group = demo_answer[demo_answer['variation'] == 'Control']\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "numerical_columns = ['age', 'tenure_year', 'number_accounts', 'bal', 'calls_6_months', 'logons_6_months']\n",
    "test_summary_mean = test_group[numerical_columns].mean().round(3).reset_index()\n",
    "test_summary_std = test_group[numerical_columns].std().round(3).reset_index()\n",
    "test_summary_var = test_group[numerical_columns].var().round(3).reset_index()\n",
    "\n",
    "control_summary_mean = control_group[numerical_columns].mean().round(3).reset_index()\n",
    "control_summary_std = control_group[numerical_columns].std().round(3).reset_index()\n",
    "control_summary_var = control_group[numerical_columns].var().round(3).reset_index()\n",
    "\n",
    "mean_summary = pd.merge(test_summary_mean, control_summary_mean, on=\"index\").rename(columns={\"0_x\":\"test\",\"0_y\":\"control\",\"index\":\"mean\"})\n",
    "std_summary = pd.merge(test_summary_std, control_summary_std, on=\"index\").rename(columns={\"0_x\":\"test\",\"0_y\":\"control\",\"index\":\"std\"})\n",
    "var_summary = pd.merge(test_summary_var, control_summary_var, on=\"index\").rename(columns={\"0_x\":\"test\",\"0_y\":\"control\",\"index\":\"var\"})\n",
    "\n",
    "\n",
    "# Check the distribution of categorical features\n",
    "categorical_columns = ['gender', 'age_group']\n",
    "test_categorical = test_group[categorical_columns].value_counts(normalize=True).round(3).reset_index()\n",
    "control_categorical = control_group[categorical_columns].value_counts(normalize=True).round(3).reset_index()\n",
    "\n",
    "test_categorical[\"order\"] = test_categorical[\"age_group\"].map(f.order_group) + test_categorical[\"gender\"].map(f.order_gender)\n",
    "test_categorical = test_categorical.sort_values(by=\"order\").set_index(\"order\", drop=True)\n",
    "control_categorical[\"order\"] = control_categorical[\"age_group\"].map(f.order_group) + control_categorical[\"gender\"].map(f.order_gender)\n",
    "control_categorical = control_categorical.sort_values(by=\"order\").set_index(\"order\", drop=True)\n",
    "\n",
    "var_summary = pd.merge(test_categorical, control_categorical, on=\"order\").rename(columns={\"proportion_x\":\"test\",\"proportion_y\":\"control\", \"gender_x\":\"gender\", \"age_group_x\":\"age_group\"}).drop(\"gender_y\", axis=1).drop(\"age_group_y\", axis=1)\n",
    "\n",
    "#display(mean_summary, std_summary, var_summary)\n",
    "#display(test_categorical.reset_index(), control_categorical.reset_index())\n",
    "var_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_grp = demo_answer[numerical_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(corr_grp, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Corr between our data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(demo_answer[\"step_reversions\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group = demo_answer[demo_answer['variation'] == 'Test']\n",
    "control_group = demo_answer[demo_answer['variation'] == 'Control']\n",
    "\n",
    "completed_test = test_group[\"completed\"].sum()\n",
    "total_test = test_group[\"completed\"].count()\n",
    "uncompleted_test = test_group[\"completed\"].count() - completed_test\n",
    "\n",
    "completed_control = control_group[\"completed\"].sum()\n",
    "total_control = control_group[\"completed\"].count() \n",
    "uncompleted_control = control_group[\"completed\"].count() - completed_control\n",
    "\n",
    "\n",
    "print(\"Test: \", completed_test, uncompleted_test)\n",
    "print(\"Control: \",  completed_control, uncompleted_control)\n",
    "\n",
    "cont_table = np.array([[completed_test, uncompleted_test], [completed_control, uncompleted_control]])\n",
    "print(cont_table)\n",
    "\n",
    "# Step 3: Perform the chi-squared test\n",
    "chi2, p_value, _, _ = chi2_contingency(cont_table)\n",
    "# Step 4: Interpret the result\n",
    "alpha = 0.05  # Significance level\n",
    "print(\"\")\n",
    "print(f\"Chi-squared statistic: {round(chi2,4)}\")\n",
    "print(f\"P-value: {round(p_value,4)}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis. Difference is statistically significant.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis. We cannot reject the difference to be just statistical variability.\")\n",
    "     \n",
    "print(\"\")\n",
    "\n",
    "success = [completed_test, completed_control]\n",
    "tests = [total_test, total_control]\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "stats, p_val = proportions_ztest(success, tests)\n",
    "print(f\"Z-test statistic: {round(stats,4)}\")\n",
    "print(f\"P-value: {round(p_val,4)}\")\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(f\"\\nBecause p_value: {round(p_val,4)} < alpha: {alpha} we can reject the null and the difference in completion rates is statistically significant.\")\n",
    "else:\n",
    "    print(f\"\\nBecause p_value: {round(p_val,4)} > alpha: {alpha}, we cannot reject the null, so we can't discard that the difference is not statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “Is the Error rate of the Test Group lesser than the Control Group?“\n",
    "demo_answer2 = demo_answer.copy()\n",
    "\n",
    "demo_answer2[\"error2\"] = demo_answer2.apply(lambda x : 1 if x[\"error\"] > 0 else 0, axis=1)\n",
    "\n",
    "test_group = demo_answer2[demo_answer2['variation'] == 'Test']\n",
    "control_group = demo_answer2[demo_answer2['variation'] == 'Control']\n",
    "\n",
    "completed_test = test_group[\"error2\"].sum()\n",
    "total_test = test_group[\"error2\"].count()\n",
    "uncompleted_test = test_group[\"error2\"].count() - completed_test\n",
    "\n",
    "completed_control = control_group[\"error2\"].sum()\n",
    "total_control = control_group[\"error2\"].count() \n",
    "uncompleted_control = control_group[\"error2\"].count() - completed_control\n",
    "\n",
    "print(\"Test: \", completed_test, uncompleted_test)\n",
    "print(\"Control: \",  completed_control, uncompleted_control)\n",
    "\n",
    "cont_table = np.array([[completed_test, uncompleted_test], [completed_control, uncompleted_control]])\n",
    "print(cont_table)\n",
    "\n",
    "# Step 3: Perform the chi-squared test\n",
    "chi2, p_value, _, _ = chi2_contingency(cont_table)\n",
    "# Step 4: Interpret the result\n",
    "alpha = 0.05  # Significance level\n",
    "print(\"\")\n",
    "print(f\"Chi-squared statistic: {round(chi2,4)}\")\n",
    "print(f\"P-value: {round(p_value,4)}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"\\nReject the null hypothesis. Difference is statistically significant.\")\n",
    "else:\n",
    "    print(\"\\nFail to reject the null hypothesis. We cannot reject the difference to be just statistical variability.\")\n",
    "     \n",
    "print(\"\")\n",
    "\n",
    "success = [completed_test, completed_control]\n",
    "tests = [total_test, total_control]\n",
    "\n",
    "# H0 : Test group's error rate is less than or equal to the Control group's error rate.\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "stats, p_val = proportions_ztest(success, tests, alternative=\"smaller\")\n",
    "\n",
    "print(f\"Z-test statistic: {round(stats, 4)}\")\n",
    "print(f\"P-value: {round(p_val, 4)}\")\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(f\"\\nBecause p_value: {round(p_val, 4)} < alpha: {alpha}, we reject H0. The Test group has a significantly smaller error rate.\")\n",
    "else:\n",
    "    print(f\"\\nBecause p_value: {round(p_val, 4)} > alpha: {alpha}, we cannot reject H0. We can't conclude the Test group has a smaller error rate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “Test takes less time to complete than Control Group?“\n",
    "\n",
    "# Filter out rows with null 'SC' (Completion times)\n",
    "demo_answer2 = demo_answer.dropna(subset=['SC'])\n",
    "\n",
    "# Split into Test and Control groups\n",
    "test_group = demo_answer2[demo_answer2['variation'] == 'Test']['SC']\n",
    "control_group = demo_answer2[demo_answer2['variation'] == 'Control']['SC']\n",
    "\n",
    "# Perform the test\n",
    "stat, p_value = st.kstest(test_group, 'norm', args=(test_group.mean(), test_group.std()))\n",
    "print(f\"Kolmogorov-Smirnov test statistic: {stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"The data is normally distributed (fail to reject H0).\")\n",
    "else:\n",
    "    print(\"The data is not normally distributed (reject H0).\")\n",
    "\n",
    "# (H0): The Test group takes either the same or longer time to complete than the Control group.\n",
    "\n",
    "# Perform a one-tailed Mann-Whitney U test (testing if Test group takes less time)\n",
    "u_stat, p_value = st.mannwhitneyu(test_group, control_group, alternative='less')\n",
    "\n",
    "print(f\"T-test statistic: {u_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"Cant reject HO: The Test group takes either the same or longer time to complete than the Control group.\")\n",
    "else:\n",
    "    print(\"Reject H0: The Test group takes less time to complete than the Control group.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
