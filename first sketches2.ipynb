{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions file\n",
    "import cleaning as cl\n",
    "\n",
    "# import modules\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from sqlalchemy import create_engine, text, inspect, Table, Column, Integer, String, MetaData, ForeignKey\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.contingency import association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importing datasheets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographic data from clients\n",
    "final_demo = pd.read_csv('sources/raw/df_final_demo.txt', sep=',')\n",
    "\n",
    "# test vs control groups\n",
    "final_exp = pd.read_csv('sources/raw/df_final_experiment_clients.txt', sep=',')\n",
    "\n",
    "# raw data from clients\n",
    "data1 = pd.read_csv('sources/raw/df_final_web_data_pt_1.txt', sep=',')\n",
    "data2 = pd.read_csv('sources/raw/df_final_web_data_pt_2.txt', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating an engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = 'new_password'\n",
    "# Create the Database\n",
    "database_name = 'project5'\n",
    "# Set Up Database Connection\n",
    "engine = create_engine(f'mysql+pymysql://root:{password}@localhost')\n",
    "# Create Database if it Doesn't Exist\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(f'CREATE DATABASE IF NOT EXISTS {database_name}'))\n",
    "# Connect to the Newly Created Database\n",
    "engine = create_engine(f'mysql+pymysql://root:{password}@localhost/{database_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **METADATA**\n",
    "- **client_id**: Every client’s unique ID.\n",
    "- **variation**: Indicates if a client was part of the experiment.\n",
    "- **visitor_id**: A unique ID for each client-device combination.\n",
    "- **visit_id**: A unique ID for each web visit/session.\n",
    "- **process_step**: Marks each step in the digital process.\n",
    "- **date_time**: Timestamp of each web activity.\n",
    "- **clnt_tenure_yr**: Represents how long the client has been with Vanguard, measured in years.\n",
    "- **clnt_tenure_mnth**: Further breaks down the client’s tenure with Vanguard in months.\n",
    "- **clnt_age**: Indicates the age of the client.\n",
    "- **gendr**: Specifies the client’s gender.\n",
    "- **num_accts**: Denotes the number of accounts the client holds with Vanguard.\n",
    "- **bal**: Gives the total balance spread across all accounts for a particular client.\n",
    "- **calls_6_mnth**: Records the number of times the client reached out over a call in the past six months.\n",
    "- **logons_6_mnth**: Reflects the frequency with which the client logged onto Vanguard’s platform over the last six months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CLEANING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first inspection on the demographics file\n",
    "display(final_demo.shape)\n",
    "display(final_demo.head())\n",
    "display(final_demo.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaN rows\n",
    "final_demo2 = final_demo[final_demo.isnull().sum(axis=1) < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender fix\n",
    "final_demo2[\"gendr\"] = final_demo2[\"gendr\"].replace({\"X\":\"U\"})\n",
    "final_demo2[\"gendr\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "final_demo2 = final_demo2.rename(columns={\"clnt_tenure_yr\":\"tenure_year\", \"clnt_tenure_mnth\":\"tenure_month\", \"clnt_age\":\"age\", \"gendr\":\"gender\",\"num_accts\":\"number_accounts\", \"calls_6_mnth\":\"calls_6_months\",\"logons_6_mnth\":\"logons_6_months\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_group(row):\n",
    "    if row < 18:\n",
    "        return \"teenager\"\n",
    "    elif row <35:\n",
    "        return \"young_adult\"\n",
    "    elif row <50:\n",
    "        return \"adult\"\n",
    "    elif row <65:\n",
    "        return \"old_adult\"\n",
    "    else:\n",
    "        return \"elder\"\n",
    "     \n",
    "\n",
    "final_demo2[\"age_group\"] = final_demo2[\"age\"].apply(age_group)\n",
    "\n",
    "display(final_demo2)\n",
    "final_demo2.to_sql(\"demo2\", con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **First visualizations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_demo3 = final_demo2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [\"tenure_month\", \"age\", \"number_accounts\",\"bal\" , \"calls_6_months\" , \"logons_6_months\"]\n",
    "def hist_box_plot(df, check):\n",
    "    for i in check:\n",
    "        plt.figure(dpi=400, figsize=(20, 2))\n",
    "        plt.subplot(1,2,1)\n",
    "        print(f\"----- DISPLAYING {i} ------------ \")\n",
    "        sns.histplot(df, x=i)\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.boxplot(df, x=i)\n",
    "        plt.show()\n",
    "\n",
    "hist_box_plot(final_demo3, check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_display(df, column_name):\n",
    "    type1 = df[column_name].value_counts().reset_index()\n",
    "    type1.columns = [column_name, 'count']  # Rename columns\n",
    "    sns.barplot(data=type1, x=column_name, y='count', hue=column_name)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "categorical_display(final_demo3, \"gender\")\n",
    "categorical_display(final_demo3, \"age_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_comparison(df, column_1, column_2):\n",
    "    type1 = df.groupby([column_1])[column_2].mean().reset_index()\n",
    "\n",
    "    type1.columns = [column_1,column_2]  # Rename columns\n",
    "    type1\n",
    "    sns.barplot(data=df, y=column_2, hue=column_1)\n",
    "    plt.legend(title=column_1, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "categorical_comparison(final_demo3, \"age_group\", \"bal\")\n",
    "\n",
    "# bal by age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'age_group' and sum 'logons_6_months'\n",
    "l1 = final_demo3.groupby([\"age_group\"])[\"logons_6_months\"].sum().reset_index()\n",
    "\n",
    "def order_group(row):\n",
    "    if row == \"teenager\":\n",
    "        return 0\n",
    "    elif row == \"young_adult\":\n",
    "        return 3\n",
    "    elif row == \"adult\":\n",
    "        return 6\n",
    "    elif row == \"old_adult\":\n",
    "        return 9\n",
    "    elif row == \"elder\":\n",
    "        return 12\n",
    "    else:\n",
    "        return \"error\"\n",
    "\n",
    "l1[\"order\"]=l1[\"age_group\"].map(order_group)\n",
    "l1 = l1.sort_values(by=\"order\")\n",
    "l1 = l1.set_index(\"order\")\n",
    "\n",
    "l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot using the aggregated counts\n",
    "sns.barplot(data=l1, x='age_group', y='logons_6_months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'age_group' and sum 'logons_6_months'\n",
    "l2 = final_demo3.groupby([\"age_group\", \"gender\"])[\"logons_6_months\"].mean().reset_index()\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_gender(row):\n",
    "    if row == \"U\":\n",
    "        return 0\n",
    "    elif row == \"M\":\n",
    "        return 1\n",
    "    elif row == \"F\":\n",
    "        return 2\n",
    "    else:\n",
    "        return \"error\"\n",
    "    \n",
    "l2[\"order\"]=l2[\"age_group\"].map(order_group)\n",
    "l2[\"order\"]=l2[\"order\"]+l2[\"gender\"].map(order_gender)\n",
    "l2 = l2.sort_values(by=\"order\")\n",
    "l2 = l2.set_index(\"order\")\n",
    "\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar plot\n",
    "sns.barplot(data=l2, x='age_group', y='logons_6_months', hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'age_group' and sum 'logons_6_months'\n",
    "l3 = final_demo3.groupby([\"age_group\", \"gender\"])[\"tenure_month\"].mean().reset_index()\n",
    "\n",
    "l3[\"order\"]=l3[\"age_group\"].map(order_group)\n",
    "l3[\"order\"]=l3[\"order\"]+l3[\"gender\"].map(order_gender)\n",
    "l3 = l3.sort_values(by=\"order\")\n",
    "l3 = l3.set_index(\"order\")\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(data=l3, x='age_group', y='tenure_month', hue='gender')\n",
    "\n",
    "# Move the legend outside the plot\n",
    "plt.legend(title='gender', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "l3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Who are the primary clients using this online process?**\n",
    "\n",
    "From these barplots we can clearly see that the primary client (the one with most usage) is the old adult category (ages between 50-65).\n",
    "Gender wise, Unspecified lead the race, with Males following close behind.\n",
    "Once all data is being grouped, we see that young adults (age 18-35) with unspecified gender have the highest usage, followed by both male and female old adults.\n",
    "\n",
    "#####  **2. Are the primary clients younger or older, new or long-standing?**\n",
    "\n",
    "Regarding tenure, we clearly see Elder (age > 65) has the higher numbers, with an average of over 200 months for both Male and Female genders, followed by teenagers (age < 18) and old adults with around 195 months on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECOND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(final_exp.shape)\n",
    "display(final_exp.head())\n",
    "final_exp.isna().sum()\n",
    "\n",
    "final_exp.to_sql(\"experience\", con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THIRD DATASET + FOURTH DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data1.shape)\n",
    "display(data1.head())\n",
    "data1.isna().sum()\n",
    "\n",
    "data1[\"process_step\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data2.shape)\n",
    "display(data2.head())\n",
    "data2.isna().sum()\n",
    "data2[\"process_step\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joins data1 and data2 files, sends to SQL\n",
    "#t_data = pd.concat([data1, data2], axis=0)\n",
    "#t_data.to_sql(\"dataset\", con = engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting A/B construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SQL, joins tables and retrieves the association between the datasheet and the variation table.\n",
    "\"\"\"\n",
    "statement = (\"\"\" \"\"\"\n",
    "            SELECT d.client_id, e.Variation, d.visitor_id, d.visit_id, d.process_step, d.date_time\n",
    "            FROM dataset as d\n",
    "            LEFT JOIN experience as e             \n",
    "            ON d.client_id = e.client_id\n",
    "            WHERE e.Variation IS NOT NULL\n",
    "            ;\n",
    "            \"\"\" \"\"\")\n",
    "with engine.connect() as con:\n",
    "    try:\n",
    "        # Execute the query to fetch results\n",
    "        answer = pd.read_sql(statement, con)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "answer.to_sql(\"dataset2\", con=engine, if_exists=\"replace\")\n",
    "answer.to_csv(\"answer.csv\")\n",
    "answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv(\"answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleanup \n",
    "\n",
    "# A Cleanup\n",
    "A_answer = answer[answer[\"Variation\"]==\"Test\"].reset_index(drop=True).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "A_answer = A_answer.drop_duplicates()\n",
    "A_answer[\"client_id\"].value_counts()\n",
    "A_answer = A_answer.drop(\"Variation\", axis=1)\n",
    "A_answer = A_answer.drop(\"client_id\", axis=1)\n",
    "A_answer = A_answer.drop(\"visitor_id\", axis=1)\n",
    "\n",
    "A_answer = A_answer.sort_values(by=[\"visit_id\",\"date_time\"]).reset_index(drop=True)\n",
    "#A_answer_visit_id = A_answer.sort_values(by=\"visit_id\")\n",
    "\n",
    "A_answer.to_csv(\"A_answer.csv\")\n",
    "\n",
    "# B Cleanup\n",
    "B_answer = answer[answer[\"Variation\"]==\"Control\"].reset_index(drop=True).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "B_answer = B_answer.drop_duplicates()\n",
    "B_answer[\"client_id\"].value_counts()\n",
    "B_answer_date = B_answer.sort_values(by=\"date_time\")\n",
    "B_answer_visit_id = B_answer.sort_values(by=\"visit_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates A_answer and B_answer copy for cleaning\n",
    "A_2 = A_answer.copy()\n",
    "B_2 = B_answer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, df_name):\n",
    "    struct = {\n",
    "        'visit_id': [],\n",
    "        'start_date': [],\n",
    "        'step_1_date': [],\n",
    "        'step_2_date': [],\n",
    "        'step_3_date': [],\n",
    "        'confirm_date': []\n",
    "    }\n",
    "\n",
    "    df_name = pd.DataFrame(struct)\n",
    "\n",
    "    # Define a mapping for process steps to their corresponding date columns\n",
    "    process_mapping = {\n",
    "        'start': 'start_date',\n",
    "        'step_1': 'step_1_date',\n",
    "        'step_2': 'step_2_date',\n",
    "        'step_3': 'step_3_date',\n",
    "        'confirm': 'confirm_date'\n",
    "    }\n",
    "\n",
    "    # Iterate over the rows in df to update or append dates\n",
    "    for index, row in df.iterrows():\n",
    "        visit_id = row['visit_id']\n",
    "        date_time = row['date_time']\n",
    "\n",
    "        # Check if visit_id exists in df_name\n",
    "        if visit_id not in df_name[\"visit_id\"].values:\n",
    "            # Create a new DataFrame for the new row\n",
    "            new_row = pd.DataFrame({'visit_id': [visit_id]})\n",
    "            df_name = pd.concat([df_name, new_row], ignore_index=True)\n",
    "\n",
    "        # Update the appropriate date column based on process_step\n",
    "        process_step = row['process_step']\n",
    "        if process_step in process_mapping:\n",
    "            date_column = process_mapping[process_step]\n",
    "            # Get the current row index in df_name\n",
    "            current_index = df_name[df_name['visit_id'] == visit_id].index[0]\n",
    "            # Only update if the date column is NaT\n",
    "            if pd.isna(df_name.at[current_index, date_column]):\n",
    "                df_name.at[current_index, date_column] = date_time\n",
    "                          \n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Runs the cleaning function, currently disabled\n",
    "# A_clean = clean_data(A_2, \"A_clean\")\n",
    "# B_clean = clean_data(B_2, \"B_clean\")\n",
    "\n",
    "# Creates the cleaned csv (as backup)\n",
    "#A_clean.to_csv(\"A_clean.csv\")\n",
    "#B_clean.to_csv(\"B_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_clean = pd.read_csv(\"A_clean.csv\")\n",
    "B_clean = pd.read_csv(\"B_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(A_clean.drop(\"Unnamed: 0\", axis=1))\n",
    "display(B_clean.drop(\"Unnamed: 0\", axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ho -> sucess rate from the new feature is equal to the old feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process flow: start -> step_1 -> step_2 -> step_3 -> confirm\n",
    "\n",
    "def ordered_grouped(row):\n",
    "    if row == \"start\":\n",
    "        return 0\n",
    "    elif row == \"step_1\":\n",
    "        return 100\n",
    "    elif row == \"step_2\":\n",
    "        return 200\n",
    "    elif row == \"step_3\":\n",
    "        return 300\n",
    "    elif row == \"confirm\":\n",
    "        return 400\n",
    "    else:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_grouped = A_answer.groupby([\"process_step\"])[\"visit_id\"].count().reset_index()\n",
    "\n",
    "A_grouped[\"ordered\"]=A_grouped[\"process_step\"].map(ordered_grouped)\n",
    "A_grouped.sort_values(by= \"ordered\", inplace=True)\n",
    "A_grouped = A_grouped.set_index(\"ordered\")\n",
    "\n",
    "A_grouped[\"percentage\"]=round(A_grouped[\"visit_id\"]/A_grouped[\"visit_id\"][0] * 100,2)\n",
    "A_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_grouped = B_answer.groupby([\"process_step\"])[\"visit_id\"].count().reset_index()\n",
    "\n",
    "B_grouped[\"ordered\"]=B_grouped[\"process_step\"].map(ordered_grouped)\n",
    "B_grouped.sort_values(by= \"ordered\", inplace=True)\n",
    "B_grouped = B_grouped.set_index(\"ordered\")\n",
    "\n",
    "B_grouped[\"percentage\"]=round(B_grouped[\"visit_id\"]/B_grouped[\"visit_id\"][0] * 100,2)\n",
    "B_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.merge(A_grouped[['process_step', 'client_id']], \n",
    "                     B_grouped[['process_step', 'client_id']], \n",
    "                     on='process_step', suffixes=('_A', '_B'))\n",
    "\n",
    "completation_rate_df = merged_df[merged_df['process_step'].isin(['start', 'confirm'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a contingency table from merged dataframes\n",
    "contingency_table = completation_rate_df[['client_id_A', 'client_id_B']]\n",
    "print(contingency_table)\n",
    "\n",
    "#Chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cramer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Computing the association between variables in 'crosstab_result' using the \"cramer\" method\n",
    "crosstab_result = pd.crosstab(contingency_table['client_id_A'], contingency_table ['client_id_B'])\n",
    "\n",
    "association(crosstab_result, method=\"cramer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing A/B Testing, we recognized that there is a statistically significant difference in completion rate between the two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first remarks\n",
    "\n",
    "From basic analysis of group A vs B we can see that from those starting, only 62% reached step1 vs our new-feature's 68.7%. However, step2 is almost tied, which seem to point out towards an issue with that step that needs improving. New features on step are worsening the score, 46% vs 48% on the old system, but the overall score (so those that complete the steps and confirm) we do see an improvement, showing that the new feature is indeed more efficient (45.6% vs 36.8% on the new feature). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ho -> % success PER age_group is equal to the old feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ho -> time per step is equal for both features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "statement = (\"\"\" \"\"\"\n",
    "            SELECT d.client_id, e.Variation, d.visitor_id, d.visit_id, d.process_step, d.date_time, f.age_group\n",
    "            FROM dataset as d\n",
    "            LEFT JOIN experience as e             \n",
    "            ON d.client_id = e.client_id\n",
    "            LEFT JOIN demo2 as f\n",
    "            ON d.client_id = f.client_id\n",
    "            WHERE e.Variation IS NOT NULL\n",
    "            ;\n",
    "            \"\"\" \"\"\")\n",
    "with engine.connect() as con:\n",
    "    try:\n",
    "        # Execute the query to fetch results\n",
    "        answer = pd.read_sql(statement, con)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "answer.to_sql(\"dataset3\", con=engine, if_exists=\"replace\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grb_df(df, dfname):\n",
    "    # groups by process_step and age_group\n",
    "    df = df.groupby([\"process_step\", \"age_group\"])[\"client_id\"].count().reset_index() \n",
    "    \n",
    "    ## orders the groups by process step & age_group by creating a new row and set it as index\n",
    "    df[\"ordered\"]=df[\"process_step\"].map(ordered_grouped)+df[\"age_group\"].map(order_group)\n",
    "    df.sort_values(by= \"ordered\", inplace=True)\n",
    "    df = df.set_index(\"ordered\")\n",
    "    \n",
    "    ## renames the columns with the dataframe name to be easier to read\n",
    "    df = df.rename(columns={\"client_id\":dfname})\n",
    "    return df\n",
    "\n",
    "def A_B_sorting(df):\n",
    "    #filters dataset (df) into the 2 variation groups\n",
    "    test_answer = df[df[\"Variation\"]==\"Test\"]\n",
    "    control_answer = df[df[\"Variation\"]==\"Control\"]\n",
    "    \n",
    "    # creates the grouped dataframes\n",
    "    test_answer = grb_df(test_answer, \"Test\")\n",
    "    control_answer = grb_df(control_answer, \"Control\")\n",
    "    \n",
    "    # joins the tables back into a single dataframe, removing any common columns.\n",
    "    ret = pd.concat([test_answer,control_answer], axis=1)\n",
    "    ret = ret.loc[:, ~ret.columns.duplicated()]\n",
    "    return ret\n",
    "      \n",
    "# returned = A_B_sorting(answer)\n",
    "\n",
    "\n",
    "# display(returned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data= returned\n",
    "# Reshape the data for better comparison\n",
    "melted_data = pd.melt(data, id_vars=['process_step', 'age_group'], value_vars=['Test', 'Control'], \n",
    "                       var_name='Group', value_name='Count')\n",
    "\n",
    "# Create a FacetGrid to plot separate plots for each age group\n",
    "g = sns.FacetGrid(melted_data, col=\"age_group\", hue=\"Group\", height=5, aspect=1.2)\n",
    "g.map(sns.lineplot, \"process_step\", \"Count\", marker='o')\n",
    "\n",
    "# Add titles and adjust the layout\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.add_legend()\n",
    "g.set_xticklabels(rotation=45)\n",
    "g.set_axis_labels(\"Process Step\", \"Count\")\n",
    "plt.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle('Test vs Control Comparison Across Process Steps by Age Group')\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.contingency import association\n",
    "\n",
    "completation_rate_df = returned[returned['process_step'].isin(['start', 'confirm'])]\n",
    "\n",
    "#Create a contingency table from merged dataframes\n",
    "contingency_table = completation_rate_df[['Test', 'Control']]\n",
    "print(contingency_table)\n",
    "\n",
    "#Chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Computing the association between variables in 'crosstab_result' using the \"cramer\" method\n",
    "crosstab_result = pd.crosstab(contingency_table['Test'], contingency_table ['Control'])\n",
    "Cramer_number = association(crosstab_result, method=\"cramer\")\n",
    "\n",
    "print(f\"Chi-square statistic: {round(chi2,2)}\")\n",
    "print(f\"P-value: {round(p_value,20)}\")\n",
    "print(f\"Cramér value: {Cramer_number}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bias = answer.groupby('age_group')['client_id'].nunique().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "bias.columns = ['age_group', 'unique_client_count']\n",
    "\n",
    "# Calculate the total unique clients across all age groups\n",
    "total_unique_clients = answer['client_id'].nunique()\n",
    "\n",
    "# Create a total row\n",
    "total_row = pd.DataFrame({'age_group': ['Total'], 'unique_client_count': [total_unique_clients]})\n",
    "\n",
    "# Concatenate the total row to the existing DataFrame\n",
    "bias = pd.concat([bias, total_row], ignore_index=True)\n",
    "bias['percentage'] = round(bias['unique_client_count'] / bias.loc[bias['age_group'] == 'Total', 'unique_client_count'].values[0] * 100,2)\n",
    "\n",
    "display(bias)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A_answer_singles = A_answer.drop_duplicates(\"visit_id\", keep=\"last\")\n",
    "A_answer_singles = A_answer_singles.drop(\"visitor_id\", axis=1)\n",
    "A_answer_singles = A_answer_singles.drop(\"Variation\", axis=1)\n",
    "\n",
    "A_answer_singles.to_csv(\"A_singles.csv\")\n",
    "\n",
    "# measuring completion rate\n",
    "A_total = A_answer_singles[[\"process_step\"]].count()\n",
    "A_completed = A_answer_singles[A_answer_singles[\"process_step\"]==\"confirm\"].count()\n",
    "\n",
    "A_completion_rate = round(float((A_completed.loc[\"process_step\"] ) / A_total.loc[\"process_step\"]),4)*100\n",
    "\n",
    "display(f\"Completion rate for test-program is {A_completion_rate}%.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "B_answer_singles = B_answer.drop_duplicates(\"visit_id\", keep=\"last\")\n",
    "B_answer_singles = B_answer_singles.drop(\"visitor_id\", axis=1)\n",
    "B_answer_singles = B_answer_singles.drop(\"Variation\", axis=1)\n",
    "\n",
    "B_answer_singles.to_csv(\"A_singles.csv\")\n",
    "\n",
    "# measuring completion rate\n",
    "B_total = B_answer_singles[[\"process_step\"]].count()\n",
    "B_completed = B_answer_singles[B_answer_singles[\"process_step\"]==\"confirm\"].count()\n",
    "\n",
    "B_completion_rate = round(float(( B_completed.loc[\"process_step\"] ) / B_total.loc[\"process_step\"]),4)*100\n",
    "\n",
    "display(f\"Completion rate for control-program is {B_completion_rate}%.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **KPI to evaluate**\n",
    "\n",
    "- Define the KPIs you chose to evaluate the new design’s performance.\n",
    "- Compare the KPIs for the Control Group vs. the Test Group.\n",
    "- Present visual aids to support the KPI analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics:\n",
    "Work objective is comparing 2 applications (one current, one new) and analyze it's perfomance (if it's better for the end user)\n",
    "\n",
    "- Is the program more user-friendly? (KPIs - %completion rate, %errors)\n",
    "- Is the program more efficient? (KPIs - Time Spent on Each Step, cost-efficient for implementation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Analyzing A/B Test Results:\n",
    "\n",
    "1. **Collect Data:** Track and gather data on how each group interacts with the content.\n",
    "2. **Statistical Analysis:** Use statistical tests (e.g., t-test) to determine if the differences observed are statistically significant.\n",
    "3. **Draw Conclusions:** If Version B significantly outperforms Version A, consider implementing the change. If not, revert to the original or consider new tests.\n",
    "\n",
    "**Note**: in this week's project, you'll be analyzing A/B Test Results, since the design and the collection of data was already done.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis Testing\n",
    "\n",
    "As part of your analysis, you’ll conduct hypothesis testing to make data-driven conclusions about the effectiveness of the redesign. See the full details below:\n",
    "\n",
    "- Completion Rate: Given the data and KPIs you have explored discussed, one interesting hypothesis to test is related to the completion rate between the Test and Control groups. Since the new design (Test group) had a higher completion rate compared to the old design (Control group), you are required to confirm if this difference is statistically significant.\n",
    "\n",
    "Make sure to define the proper null and an alternative hypothesis to test it. Use the provided data to test these hypotheses, and determine if you can reject the null hypothesis in favor of the alternative. Make sure to consider the significance level, p-value, the statistical test prerequisites, and other relevant statistical measures in your analysis.\n",
    "\n",
    "- Completion Rate with a Cost-Effectiveness Threshold: The introduction of a new UI design comes with its associated costs: design, development, testing, potential training for staff, and possible short-term disruptions or adjustments for users. To justify these costs, Vanguard has determined that any new design should lead to a minimum increase in the completion rate to be deemed cost-effective.\n",
    "\n",
    "Threshold: Vanguard has set this minimum increase in completion rate at 5%. This is the rate at which the projected benefits, in terms of increased user engagement and potential revenue, are estimated to outweigh the costs of the new design.\n",
    "\n",
    "You are required to carry out another analysis, ensuring that the observed increase in completion rate from the A/B test meets or exceeds this 5% threshold. If the new design doesn’t lead to at least this level of improvement, it may not be justifiable from a cost perspective, regardless of its statistical significance.\n",
    "\n",
    "- Other Hypothesis Examples\n",
    "You have been given the freedom to choose another hypothesis to test. Here are some examples:\n",
    "\n",
    "You might want to test whether the average age of clients engaging with the new process is the same as those engaging with the old process\n",
    "You might want to test if the average client tenure (how long they’ve been with Vanguard) of those engaging with the new process is the same as those engaging with the old process\n",
    "You might want to test if there are gender differences that affect engaging with the new or old process\n",
    "Make sure to define the proper null and alternative hypothesis to test it. You are required to choose one or come up with another of your own to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_future = answer[answer['Variation'] == 'Control']\n",
    "completation = old_future[old_future['process_step'].isin(['start', 'confirm'])]\n",
    "completation['process_step'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
